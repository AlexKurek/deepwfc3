The synthetic model used the LeNet architecture (2 convolutional layers and 3 fully connected layers), but with different hyperparameters (see [insert ISR link]). The synthetic model trained for 10 epochs, or trained over the entire training set 10 times. It also trained with a batch size of 128, or trained using 128 samples in one iteration of training.
