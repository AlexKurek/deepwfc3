{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WFC3 Figure 8 Ghost Classification using GoogLeNet\n",
    "---\n",
    "\n",
    "The purpose of the notebook is to demonstrate how to use a DeepWFC3 model to predict if a WFC3 image contains a Figure 8 Ghost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a id=\"imports\"></a>\n",
    "\n",
    "If you are running this notebook in Jupyter, this notebook assumes you created the virtual environment defined in `environment.yml`. If not, close this notebook and run the following lines in a terminal window:\n",
    "\n",
    "`conda env create -f environment.yml`\n",
    "\n",
    "`conda activate deepwfc3_env`\n",
    "\n",
    "We import the following libraries:\n",
    "- *numpy* for handling arrays\n",
    "- *matplotlib* for plotting\n",
    "- *torch* as our machine learning framework\n",
    "\n",
    "We also import functions from `utils.py` to load the model and plot saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from utils import load_wfc3_uvis_figure8_model, saliency_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "`examples.npz` is a compressed numpy file containing two WFC3 images post processing pipeline (see (insert py file name here)). The first image is a null image of the galaxy N5643 (idgg69pmq) and the second is the globular cluster NGC-6752 (ibhf01sjq), which contains a figure 8 ghost.\n",
    "\n",
    "We load the images using `np.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.Tensor(np.load('examples.npz')['examples'])\n",
    "example_0 = example[0].reshape(1,1,256,256)\n",
    "example_1 = example[1].reshape(1,1,256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "This model uses 3 convolutional layers and 3 fully connected layers.  The model was first trained on synthetic data where figure 8's were inserted onto images randomly [ISR REF HERE].  After converging to a high accuracy on the synthetic data, the parameters of the convolutional layers were frozen, though the parameters were allowed to vary.  The fully connected layers were then retrained on real data.\n",
    "\n",
    "The model is saved as `wfc3_uvis_figure8_model_c.torch` and can be loaded using `load_wfc3_uvis_figure8_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_wfc3_uvis_figure8_model('wfc3_uvis_figure8_model_c.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Examples\n",
    "\n",
    "To predict the example classifications, we use them as arguments for `model()`, which returns the last two output neurons. The index of the greatest neuron output is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0 = model(example_0)\n",
    "pred_1 = model(example_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Example 0 Output Neurons: {}'.format(pred_0))\n",
    "print ('Example 1 Output Neurons: {}'.format(pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Saliency Maps\n",
    "\n",
    "We can view the [saliency maps](https://arxiv.org/pdf/1312.6034.pdf) our model produces for the examples by using `saliency_map()`, which prints the prediction probabilities, and plots the original image and the saliency map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = saliency_map(model, example[0].reshape(1,1,256,256))\n",
    "sm = saliency_map(model, example[1].reshape(1,1,256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions <a id=\"con\"></a>\n",
    "\n",
    "Thank you for walking through this notebook. Now you should be more familiar with using our model to predict if figure 8 ghosts are on WFC3 images.\n",
    "\n",
    "## About this Notebook <a id=\"about\"></a>\n",
    "\n",
    "**Author:** Varun Bajaj, Fred Dauphin, DeepWFC3\n",
    "\n",
    "**Updated on:** 2022-01-14\n",
    "\n",
    "## Citations <a id=\"cite\"></a>\n",
    "\n",
    "If you use `numpy`, `matplotlib`, or `torch` for published research, please cite the authors. Follow these links for more information about citing `numpy`, `matplotlib`, and `torch`:\n",
    "\n",
    "* [Citing `numpy`](https://numpy.org/doc/stable/license.html)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/license.html#:~:text=Matplotlib%20only%20uses%20BSD%20compatible,are%20acceptable%20in%20matplotlib%20toolkits.)\n",
    "* [Citing `torch`](https://github.com/pytorch/pytorch/blob/master/LICENSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
