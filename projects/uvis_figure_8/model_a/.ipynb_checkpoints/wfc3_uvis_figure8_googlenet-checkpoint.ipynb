{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WFC3 Figure 8 Ghost Classification using GoogLeNet\n",
    "---\n",
    "\n",
    "The purpose of the notebook is to demonstrate how to use a DeepWFC3 model to predict if a WFC3 image contains a Figure 8 Ghost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a id=\"imports\"></a>\n",
    "\n",
    "If you are running this notebook in Jupyter, this notebook assumes you created the virtual environment defined in `environment.yml`. If not, close this notebook and run the following lines in a terminal window:\n",
    "\n",
    "`conda env create -f environment.yml`\n",
    "\n",
    "`conda activate deepwfc3_env`\n",
    "\n",
    "We import the following libraries:\n",
    "- *numpy* for handling arrays\n",
    "- *matplotlib* for plotting\n",
    "- *torch* as our machine learning framework\n",
    "\n",
    "We also import functions from `utils.py` to process images to ImageNet format, load the model, and plot saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils import process_image, load_wfc3_uvis_figure8_model, saliency_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "`examples.npz` is a compressed numpy file containing two WFC3 images post processing pipeline (see (insert py file name here)). The first image is a null image of the galaxy N5643 (idgg69pmq) and the second is the globular cluster NGC-6752 (ibhf01sjq), which contains a figure 8 ghost.\n",
    "\n",
    "We load the images using `np.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.load('examples.npz')['examples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data to ImageNet \n",
    "\n",
    "Since our model was pretrained using [ImageNet](https://www.image-net.org/), we need to scale our examples to match the statistics of the dataset. We do this by:\n",
    "- min-max scaling the images to have a minimum/maximum pixel value of 0/1\n",
    "- making three copies of our examples to use as \"RGB channels\"\n",
    "- center cropping to a 224x224\n",
    "- normalizing the channels to $N(\\mu=(0.485, 0.456, 0.406), \\sigma=(0.229, 0.224, 0.225))$\n",
    "\n",
    "See some [documentation](https://pytorch.org/hub/pytorch_vision_googlenet/) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_0_process = process_image(example[0])\n",
    "example_1_process = process_image(example[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Our model uses the [GoogLeNet](https://arxiv.org/pdf/1409.4842.pdf) architecture. The convolutional layers are frozen, and the fully conneted layers were retrained using the dataset described in (insert ISR and hyperlink here). We modify the fully connected layers to append two 1024 neuron layers with dropout rates of 0.5 and ReLU activation. Finally, we append one additional 2 neuron (number of classifications) layer with a dropout rate of 0.2 and linear activation.\n",
    "\n",
    "The model is saved as `wfc3_uvis_figure8_model.torch` and can be loaded using `load_wfc3_uvis_figure8_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_wfc3_uvis_figure8_model('wfc3_uvis_figure8_model.torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Examples\n",
    "\n",
    "To predict the example classifications, we use them as arguments for `model()`, which returns the last two output neurons. The index of the greatest neuron output is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0 = model(example_0_process)\n",
    "pred_1 = model(example_1_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Example 0 Output Neurons: {}'.format(pred_0))\n",
    "print ('Example 1 Output Neurons: {}'.format(pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Saliency Maps\n",
    "\n",
    "We can view the [saliency maps](https://arxiv.org/pdf/1312.6034.pdf) our model produces for the examples by using `saliency_map()`, which prints the prediction probabilities, and plots the original image and the saliency map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = saliency_map(model, example_0_process)\n",
    "sm = saliency_map(model, example_1_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions <a id=\"con\"></a>\n",
    "\n",
    "Thank you for walking through this notebook. Now you should be more familiar with using our model to predict if figure 8 ghosts are on WFC3 images.\n",
    "\n",
    "## About this Notebook <a id=\"about\"></a>\n",
    "\n",
    "**Author:** Fred Dauphin, DeepWFC3\n",
    "\n",
    "**Updated on:** 2022-01-14\n",
    "\n",
    "## Citations <a id=\"cite\"></a>\n",
    "\n",
    "If you use `numpy`, `matplotlib`, or `torch` for published research, please cite the authors. Follow these links for more information about citing `numpy`, `matplotlib`, and `torch`:\n",
    "\n",
    "* [Citing `numpy`](https://numpy.org/doc/stable/license.html)\n",
    "* [Citing `matplotlib`](https://matplotlib.org/stable/users/project/license.html#:~:text=Matplotlib%20only%20uses%20BSD%20compatible,are%20acceptable%20in%20matplotlib%20toolkits.)\n",
    "* [Citing `torch`](https://github.com/pytorch/pytorch/blob/master/LICENSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
